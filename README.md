# misogynistic-text-detector

This repository hosts a classifier to detect misogynistic speech by leveraging transfer learning from Bidirectional Encoder Representations from Transformers (BERT) for a small number of expert-tagged imbalanced samples.

![nirbhaya](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSG_Exwl5cgaL7gM4y2TCC-qvOHRQWmzBqGQw&usqp=CAU)![feminist_philosophy](https://upload.wikimedia.org/wikipedia/commons/thumb/d/d8/Feminist_philosophy.svg/100px-Feminist_philosophy.svg.png)

### The Dataset

The data set is composed of **2,285** definitions gathered from the Urban Dictionary platform from 1999 to 2006. The data was classified as `misogynistic` and `non-misogynistic` by three independent researchers with specialized domain knowledge. The data set is essentially a table containing two columns: the text-based definition from Urban Dictionary and its respective classification; label **1** for `misogynistic` and label **0** for `non-misogynistic` text.

![#f03c15](https://via.placeholder.com/15/f03c15/000000?text=+) **Content warning: sexual violence, extreme misogyny, scatology, ‘scat porn’.**

#### Citations

*Lynn, Theodore; Endo, Patricia; Rosati, Pierangelo; Silva, Ivanovitch; Santos, Guto Leoni; Ging, Debbie (2019) “Urban Dictionary definitions dataset for misogyny speech detection”, Mendeley Data, v3*

https://data.mendeley.com/datasets/3jfwsdkryy/3
